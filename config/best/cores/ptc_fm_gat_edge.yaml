data_kwargs.splits: [0.6, 0.3, 0.1]
early_stopping_kwargs.ppo_kwargs.metric: training/ppo_rewards___max
early_stopping_kwargs.ppo_kwargs.patience: 5
cores.env_steps: 32
cores.ppo_steps: 3
graph_env_kwargs.penalty_size: 0.5
lr_scheduler_kwargs_rl.factor: 0.9
optimizer_kwargs_rl.ratio_clf: 2.5
optimizer_kwargs_rl.ratio_critic: 1.0
ppo_kwargs.coeff_entropy: 0.01
ppo_kwargs.coeff_mse: 0.5
ppo_kwargs.eps_clip: 0.2
reward_kwargs.alpha: 0.1
reward_kwargs.desired_ratio: 0.4
reward_kwargs.lambda_1: 0.7
data: ptc_fm
graph_clf: gat
cores.action_refers_to: edge
reward_kwargs.k: 1.0
